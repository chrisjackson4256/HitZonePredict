{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game of Zones: Using Machine Learning to Predict the Outcome of an MLB At Bat\n",
    "\n",
    "Goal: predict where the batter is most likely to hit the ball (zones of the field) in an at-bat given the situation and the pitcher he is facing\n",
    "    \n",
    "Input Data: \n",
    "- the pitcher's repertoire: given that each pitcher has a different arsenal of pitches and each pitch moves differently, we use a cluster analysis to categorize pitch types.  In this way, we put each pitcher on the same footing.\n",
    "\n",
    "- the game situation: the inning (and top/bottom), the number of outs, positions of baserunners, the count, positions of fielders(?)\n",
    "\n",
    "- the batter's priors: distribution of batted balls into zones\n",
    "\n",
    "Output: \n",
    "- probabilities for each zone on the field where the batter can hit the ball\n",
    "\n",
    "- contributing factors for each prediction (things the defensive team could use to intervene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pybaseball import statcast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "%matplotlib inline\n",
    "\n",
    "from get_data import get_data, get_hit_zone, get_pitch_data\n",
    "from pitch_clustering import pitch_clustering\n",
    "\n",
    "# use Statcast data (from 2015-2018) so we can get spin rate, etc.\n",
    "train_data_dates = [('2015-04-05', '2015-10-04')] #,\n",
    "#                     ('2016-04-03', '2016-10-02'),\n",
    "#                     ('2017-04-02', '2017-10-01'),\n",
    "#                     ('2018-03-29', '2018-10-01')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a large query, it may take a moment to complete\n",
      "Completed sub-query from 2015-04-05 to 2015-04-10\n",
      "Completed sub-query from 2015-04-11 to 2015-04-16\n",
      "Completed sub-query from 2015-04-17 to 2015-04-22\n",
      "Completed sub-query from 2015-04-23 to 2015-04-28\n",
      "Completed sub-query from 2015-04-29 to 2015-05-04\n",
      "Completed sub-query from 2015-05-05 to 2015-05-10\n",
      "Completed sub-query from 2015-05-11 to 2015-05-16\n",
      "Completed sub-query from 2015-05-17 to 2015-05-22\n",
      "Completed sub-query from 2015-05-23 to 2015-05-28\n",
      "Completed sub-query from 2015-05-29 to 2015-06-03\n",
      "Completed sub-query from 2015-06-04 to 2015-06-09\n",
      "Completed sub-query from 2015-06-10 to 2015-06-15\n",
      "Completed sub-query from 2015-06-16 to 2015-06-21\n",
      "Completed sub-query from 2015-06-22 to 2015-06-27\n",
      "Completed sub-query from 2015-06-28 to 2015-07-03\n",
      "Completed sub-query from 2015-07-04 to 2015-07-09\n",
      "Completed sub-query from 2015-07-10 to 2015-07-15\n",
      "Completed sub-query from 2015-07-16 to 2015-07-21\n",
      "Completed sub-query from 2015-07-22 to 2015-07-27\n",
      "Completed sub-query from 2015-07-28 to 2015-08-02\n",
      "Completed sub-query from 2015-08-03 to 2015-08-08\n",
      "Completed sub-query from 2015-08-09 to 2015-08-14\n",
      "Completed sub-query from 2015-08-15 to 2015-08-20\n",
      "Completed sub-query from 2015-08-21 to 2015-08-26\n",
      "Completed sub-query from 2015-08-27 to 2015-09-01\n",
      "Completed sub-query from 2015-09-02 to 2015-09-07\n",
      "Completed sub-query from 2015-09-08 to 2015-09-13\n",
      "Completed sub-query from 2015-09-14 to 2015-09-19\n",
      "Completed sub-query from 2015-09-20 to 2015-09-25\n",
      "Completed sub-query from 2015-09-26 to 2015-10-01\n",
      "Completed sub-query from 2015-10-02 to 2015-10-04\n",
      "(87199, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_pk</th>\n",
       "      <th>index</th>\n",
       "      <th>batter</th>\n",
       "      <th>pitcher</th>\n",
       "      <th>hit_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>416079</td>\n",
       "      <td>239</td>\n",
       "      <td>150029</td>\n",
       "      <td>544727</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>416079</td>\n",
       "      <td>264</td>\n",
       "      <td>547180</td>\n",
       "      <td>544727</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>416079</td>\n",
       "      <td>330</td>\n",
       "      <td>543685</td>\n",
       "      <td>544727</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>416079</td>\n",
       "      <td>395</td>\n",
       "      <td>502517</td>\n",
       "      <td>595014</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>416079</td>\n",
       "      <td>529</td>\n",
       "      <td>434158</td>\n",
       "      <td>595014</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    game_pk  index  batter  pitcher  hit_zone\n",
       "0    416079    239  150029   544727         4\n",
       "2    416079    264  547180   544727         2\n",
       "10   416079    330  543685   544727         1\n",
       "15   416079    395  502517   595014         2\n",
       "24   416079    529  434158   595014         4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the outcome data\n",
    "outcome_data = get_data(get_hit_zone, train_data_dates)\n",
    "\n",
    "# write to file\n",
    "outcome_data.to_csv(\"./outcome_4zones.csv\", index=False)\n",
    "\n",
    "print(f\"Shape of the outcome data: {outcome_data.shape}\")\n",
    "outcome_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Pitcher Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Pitch Data from Baseball Savant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a large query, it may take a moment to complete\n",
      "Completed sub-query from 2015-04-05 to 2015-04-10\n",
      "Completed sub-query from 2015-04-11 to 2015-04-16\n",
      "Completed sub-query from 2015-04-17 to 2015-04-22\n",
      "Completed sub-query from 2015-04-23 to 2015-04-28\n",
      "Completed sub-query from 2015-04-29 to 2015-05-04\n",
      "Completed sub-query from 2015-05-05 to 2015-05-10\n",
      "Completed sub-query from 2015-05-11 to 2015-05-16\n",
      "Completed sub-query from 2015-05-17 to 2015-05-22\n",
      "Completed sub-query from 2015-05-23 to 2015-05-28\n",
      "Completed sub-query from 2015-05-29 to 2015-06-03\n",
      "Completed sub-query from 2015-06-04 to 2015-06-09\n",
      "Completed sub-query from 2015-06-10 to 2015-06-15\n",
      "Completed sub-query from 2015-06-16 to 2015-06-21\n",
      "Completed sub-query from 2015-06-22 to 2015-06-27\n",
      "Completed sub-query from 2015-06-28 to 2015-07-03\n",
      "Completed sub-query from 2015-07-04 to 2015-07-09\n",
      "Completed sub-query from 2015-07-10 to 2015-07-15\n",
      "Completed sub-query from 2015-07-16 to 2015-07-21\n",
      "Completed sub-query from 2015-07-22 to 2015-07-27\n",
      "Completed sub-query from 2015-07-28 to 2015-08-02\n",
      "Completed sub-query from 2015-08-03 to 2015-08-08\n",
      "Completed sub-query from 2015-08-09 to 2015-08-14\n",
      "Completed sub-query from 2015-08-15 to 2015-08-20\n",
      "Completed sub-query from 2015-08-21 to 2015-08-26\n",
      "Completed sub-query from 2015-08-27 to 2015-09-01\n",
      "Completed sub-query from 2015-09-02 to 2015-09-07\n",
      "Completed sub-query from 2015-09-08 to 2015-09-13\n",
      "Completed sub-query from 2015-09-14 to 2015-09-19\n",
      "Completed sub-query from 2015-09-20 to 2015-09-25\n",
      "Completed sub-query from 2015-09-26 to 2015-10-01\n",
      "Completed sub-query from 2015-10-02 to 2015-10-04\n",
      "Index(['index', 'pitch_type', 'game_date', 'release_speed', 'release_pos_x',\n",
      "       'release_pos_z', 'player_name', 'batter', 'pitcher', 'events',\n",
      "       'description', 'spin_dir', 'spin_rate_deprecated',\n",
      "       'break_angle_deprecated', 'break_length_deprecated', 'zone', 'des',\n",
      "       'game_type', 'stand', 'p_throws', 'home_team', 'away_team', 'type',\n",
      "       'hit_location', 'bb_type', 'balls', 'strikes', 'game_year', 'pfx_x',\n",
      "       'pfx_z', 'plate_x', 'plate_z', 'on_3b', 'on_2b', 'on_1b',\n",
      "       'outs_when_up', 'inning', 'inning_topbot', 'hc_x', 'hc_y',\n",
      "       'tfs_deprecated', 'tfs_zulu_deprecated', 'fielder_2', 'umpire', 'sv_id',\n",
      "       'vx0', 'vy0', 'vz0', 'ax', 'ay', 'az', 'sz_top', 'sz_bot',\n",
      "       'hit_distance_sc', 'launch_speed', 'launch_angle', 'effective_speed',\n",
      "       'release_spin_rate', 'release_extension', 'game_pk', 'pitcher.1',\n",
      "       'fielder_2.1', 'fielder_3', 'fielder_4', 'fielder_5', 'fielder_6',\n",
      "       'fielder_7', 'fielder_8', 'fielder_9', 'release_pos_y',\n",
      "       'estimated_ba_using_speedangle', 'estimated_woba_using_speedangle',\n",
      "       'woba_value', 'woba_denom', 'babip_value', 'iso_value',\n",
      "       'launch_speed_angle', 'at_bat_number', 'pitch_number', 'pitch_name',\n",
      "       'home_score', 'away_score', 'bat_score', 'fld_score', 'post_away_score',\n",
      "       'post_home_score', 'post_bat_score', 'post_fld_score',\n",
      "       'if_fielding_alignment', 'of_fielding_alignment'],\n",
      "      dtype='object')\n",
      "Number of pitchers in the data: 735\n",
      "Shape of training data: (650407, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pitcher</th>\n",
       "      <th>player_name</th>\n",
       "      <th>release_speed</th>\n",
       "      <th>release_spin_rate</th>\n",
       "      <th>release_extension</th>\n",
       "      <th>pfx_x</th>\n",
       "      <th>pfx_z</th>\n",
       "      <th>plate_x</th>\n",
       "      <th>plate_z</th>\n",
       "      <th>vx0</th>\n",
       "      <th>vy0</th>\n",
       "      <th>vz0</th>\n",
       "      <th>ax</th>\n",
       "      <th>ay</th>\n",
       "      <th>az</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>544727.0</td>\n",
       "      <td>Jeurys Familia</td>\n",
       "      <td>97.2</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>6.125</td>\n",
       "      <td>-1.118083</td>\n",
       "      <td>0.455133</td>\n",
       "      <td>-0.707</td>\n",
       "      <td>2.022</td>\n",
       "      <td>3.602</td>\n",
       "      <td>-141.273</td>\n",
       "      <td>-6.540</td>\n",
       "      <td>-14.347</td>\n",
       "      <td>32.145</td>\n",
       "      <td>-28.506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>544727.0</td>\n",
       "      <td>Jeurys Familia</td>\n",
       "      <td>97.5</td>\n",
       "      <td>2093.0</td>\n",
       "      <td>6.030</td>\n",
       "      <td>-1.108342</td>\n",
       "      <td>0.711700</td>\n",
       "      <td>0.442</td>\n",
       "      <td>3.496</td>\n",
       "      <td>6.394</td>\n",
       "      <td>-141.716</td>\n",
       "      <td>-3.746</td>\n",
       "      <td>-14.306</td>\n",
       "      <td>32.100</td>\n",
       "      <td>-24.835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>544727.0</td>\n",
       "      <td>Jeurys Familia</td>\n",
       "      <td>98.4</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>6.359</td>\n",
       "      <td>-1.523058</td>\n",
       "      <td>0.523933</td>\n",
       "      <td>-0.353</td>\n",
       "      <td>2.446</td>\n",
       "      <td>5.481</td>\n",
       "      <td>-143.007</td>\n",
       "      <td>-5.675</td>\n",
       "      <td>-20.489</td>\n",
       "      <td>36.599</td>\n",
       "      <td>-27.465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>544727.0</td>\n",
       "      <td>Jeurys Familia</td>\n",
       "      <td>97.7</td>\n",
       "      <td>2099.0</td>\n",
       "      <td>6.275</td>\n",
       "      <td>-1.285083</td>\n",
       "      <td>0.618533</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>1.273</td>\n",
       "      <td>5.577</td>\n",
       "      <td>-141.819</td>\n",
       "      <td>-8.799</td>\n",
       "      <td>-16.942</td>\n",
       "      <td>31.897</td>\n",
       "      <td>-26.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>544727.0</td>\n",
       "      <td>Jeurys Familia</td>\n",
       "      <td>98.2</td>\n",
       "      <td>2155.0</td>\n",
       "      <td>6.538</td>\n",
       "      <td>-0.997008</td>\n",
       "      <td>0.803433</td>\n",
       "      <td>-0.406</td>\n",
       "      <td>1.560</td>\n",
       "      <td>3.987</td>\n",
       "      <td>-142.748</td>\n",
       "      <td>-8.509</td>\n",
       "      <td>-12.709</td>\n",
       "      <td>36.274</td>\n",
       "      <td>-23.516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pitcher     player_name  release_speed  release_spin_rate  \\\n",
       "0  544727.0  Jeurys Familia           97.2             2018.0   \n",
       "1  544727.0  Jeurys Familia           97.5             2093.0   \n",
       "2  544727.0  Jeurys Familia           98.4             1960.0   \n",
       "3  544727.0  Jeurys Familia           97.7             2099.0   \n",
       "4  544727.0  Jeurys Familia           98.2             2155.0   \n",
       "\n",
       "   release_extension     pfx_x     pfx_z  plate_x  plate_z    vx0      vy0  \\\n",
       "0              6.125 -1.118083  0.455133   -0.707    2.022  3.602 -141.273   \n",
       "1              6.030 -1.108342  0.711700    0.442    3.496  6.394 -141.716   \n",
       "2              6.359 -1.523058  0.523933   -0.353    2.446  5.481 -143.007   \n",
       "3              6.275 -1.285083  0.618533   -0.054    1.273  5.577 -141.819   \n",
       "4              6.538 -0.997008  0.803433   -0.406    1.560  3.987 -142.748   \n",
       "\n",
       "     vz0      ax      ay      az  \n",
       "0 -6.540 -14.347  32.145 -28.506  \n",
       "1 -3.746 -14.306  32.100 -24.835  \n",
       "2 -5.675 -20.489  36.599 -27.465  \n",
       "3 -8.799 -16.942  31.897 -26.150  \n",
       "4 -8.509 -12.709  36.274 -23.516  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the outcome data\n",
    "pitch_data = get_data(get_pitch_data, train_data_dates)\n",
    "\n",
    "# write to file\n",
    "pitch_data.to_csv(\"./pitch.csv\", index=False)\n",
    "\n",
    "# print the number of pitchers in the data set\n",
    "print(f\"Number of pitchers in the data: {len(pitch_data['pitcher'].unique())}\")\n",
    "\n",
    "# drop rows with missing values\n",
    "pitch_data.dropna(inplace=True)\n",
    "print(f\"Shape of training data: {pitch_data.shape}\")\n",
    "      \n",
    "# extract the pitcherID column\n",
    "pitcherID = pitch_data[['pitcher', 'player_name']]\n",
    "pitch_data = pitch_data.drop(['pitcher', 'player_name'], axis=1)\n",
    "\n",
    "pitch_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components from PCA: 7\n"
     ]
    }
   ],
   "source": [
    "pitch_clustering(pitch_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescale the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>release_speed</th>\n",
       "      <th>release_spin_rate</th>\n",
       "      <th>release_extension</th>\n",
       "      <th>pfx_x</th>\n",
       "      <th>pfx_z</th>\n",
       "      <th>plate_x</th>\n",
       "      <th>plate_z</th>\n",
       "      <th>vx0</th>\n",
       "      <th>vy0</th>\n",
       "      <th>vz0</th>\n",
       "      <th>ax</th>\n",
       "      <th>ay</th>\n",
       "      <th>az</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.898529</td>\n",
       "      <td>0.506169</td>\n",
       "      <td>0.547715</td>\n",
       "      <td>0.336825</td>\n",
       "      <td>0.456100</td>\n",
       "      <td>0.516871</td>\n",
       "      <td>0.392762</td>\n",
       "      <td>0.577133</td>\n",
       "      <td>0.101997</td>\n",
       "      <td>0.331849</td>\n",
       "      <td>0.281855</td>\n",
       "      <td>0.620331</td>\n",
       "      <td>0.410816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.902941</td>\n",
       "      <td>0.531177</td>\n",
       "      <td>0.539428</td>\n",
       "      <td>0.338419</td>\n",
       "      <td>0.496921</td>\n",
       "      <td>0.577726</td>\n",
       "      <td>0.494795</td>\n",
       "      <td>0.643021</td>\n",
       "      <td>0.097651</td>\n",
       "      <td>0.419270</td>\n",
       "      <td>0.282395</td>\n",
       "      <td>0.619328</td>\n",
       "      <td>0.469035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.916176</td>\n",
       "      <td>0.486829</td>\n",
       "      <td>0.568126</td>\n",
       "      <td>0.270553</td>\n",
       "      <td>0.467047</td>\n",
       "      <td>0.535620</td>\n",
       "      <td>0.422112</td>\n",
       "      <td>0.621475</td>\n",
       "      <td>0.084986</td>\n",
       "      <td>0.358914</td>\n",
       "      <td>0.200964</td>\n",
       "      <td>0.719600</td>\n",
       "      <td>0.427325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.533178</td>\n",
       "      <td>0.560799</td>\n",
       "      <td>0.309497</td>\n",
       "      <td>0.482098</td>\n",
       "      <td>0.551456</td>\n",
       "      <td>0.340915</td>\n",
       "      <td>0.623740</td>\n",
       "      <td>0.096640</td>\n",
       "      <td>0.261168</td>\n",
       "      <td>0.247679</td>\n",
       "      <td>0.614803</td>\n",
       "      <td>0.448180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.913235</td>\n",
       "      <td>0.551851</td>\n",
       "      <td>0.583740</td>\n",
       "      <td>0.356639</td>\n",
       "      <td>0.511517</td>\n",
       "      <td>0.532813</td>\n",
       "      <td>0.360782</td>\n",
       "      <td>0.586218</td>\n",
       "      <td>0.087527</td>\n",
       "      <td>0.270242</td>\n",
       "      <td>0.303428</td>\n",
       "      <td>0.712356</td>\n",
       "      <td>0.489953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   release_speed  release_spin_rate  release_extension     pfx_x     pfx_z  \\\n",
       "0       0.898529           0.506169           0.547715  0.336825  0.456100   \n",
       "1       0.902941           0.531177           0.539428  0.338419  0.496921   \n",
       "2       0.916176           0.486829           0.568126  0.270553  0.467047   \n",
       "3       0.905882           0.533178           0.560799  0.309497  0.482098   \n",
       "4       0.913235           0.551851           0.583740  0.356639  0.511517   \n",
       "\n",
       "    plate_x   plate_z       vx0       vy0       vz0        ax        ay  \\\n",
       "0  0.516871  0.392762  0.577133  0.101997  0.331849  0.281855  0.620331   \n",
       "1  0.577726  0.494795  0.643021  0.097651  0.419270  0.282395  0.619328   \n",
       "2  0.535620  0.422112  0.621475  0.084986  0.358914  0.200964  0.719600   \n",
       "3  0.551456  0.340915  0.623740  0.096640  0.261168  0.247679  0.614803   \n",
       "4  0.532813  0.360782  0.586218  0.087527  0.270242  0.303428  0.712356   \n",
       "\n",
       "         az  \n",
       "0  0.410816  \n",
       "1  0.469035  \n",
       "2  0.427325  \n",
       "3  0.448180  \n",
       "4  0.489953  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "train_data_scaled = pd.DataFrame(scaler.fit_transform(train_data))\n",
    "train_data_scaled.columns = train_data.columns\n",
    "\n",
    "train_data_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use PCA to Reduce Dimensionality of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the PCA algorithm with our Data\n",
    "pca = PCA().fit(train_data_scaled)\n",
    "\n",
    "#Plotting the Cumulative Summation of the Explained Variance\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)') #for each component\n",
    "plt.title('Pitch Dataset Explained Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit/Transform using the number of components that get us to 98% variance explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=7)\n",
    "train_data_pca = pd.DataFrame(pca.fit_transform(train_data_scaled))\n",
    "train_data_pca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Clustering of the Pitch Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use the Elbow method to find optimal k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# range of number of clusters\n",
    "num_clusters = range(3, 16)\n",
    "\n",
    "# initiate the models\n",
    "kmeans = []\n",
    "for i in num_clusters:\n",
    "    print(f\"initializing a model for {i} clusters\")\n",
    "    kmeans.append(KMeans(n_clusters=i, n_jobs=-1))\n",
    "\n",
    "# compute the scores for each fit\n",
    "score = []\n",
    "for i, k in enumerate(num_clusters):\n",
    "    print(f\"fitting the data to {k} clusters\")\n",
    "    score.append(kmeans[i].fit(train_data_pca).score(train_data_pca))\n",
    "\n",
    "# # cluster labels\n",
    "# cluster_labels = []\n",
    "# for i, k in enumerate(num_clusters):\n",
    "#     print(f\"labeling the data for {k} clusters\")\n",
    "#     cluster_labels.append(kmeans[i].fit_predict(train_data_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(num_clusters, score)\n",
    "plt.title(\"Elbow Curve\")\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"K-Means Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-means with Gap statistic to find optimal k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimalK(data, nrefs=3, maxClusters=15):\n",
    "    \"\"\"\n",
    "    Calculates KMeans optimal K using Gap Statistic from Tibshirani, Walther, Hastie\n",
    "    Params:\n",
    "        data: ndarry of shape (n_samples, n_features)\n",
    "        nrefs: number of sample reference datasets to create\n",
    "        maxClusters: Maximum number of clusters to test for\n",
    "    Returns: (gaps, optimalK)\n",
    "    \"\"\"\n",
    "    gaps = np.zeros((len(range(1, maxClusters)),))\n",
    "    resultsdf = pd.DataFrame({'clusterCount':[], 'gap':[]})\n",
    "    for gap_index, k in enumerate(range(1, maxClusters)):\n",
    "\n",
    "        # Holder for reference dispersion results\n",
    "        refDisps = np.zeros(nrefs)\n",
    "\n",
    "        # For n references, generate random sample and perform kmeans getting resulting dispersion of each loop\n",
    "        for i in range(nrefs):\n",
    "            \n",
    "            # Create new random reference set\n",
    "            randomReference = np.random.random_sample(size=data.shape)\n",
    "            \n",
    "            # Fit to it\n",
    "            km = KMeans(k, n_jobs=-1)\n",
    "            km.fit(randomReference)\n",
    "            \n",
    "            refDisp = km.inertia_\n",
    "            refDisps[i] = refDisp\n",
    "\n",
    "        # Fit cluster to original data and create dispersion\n",
    "        km = KMeans(k)\n",
    "        km.fit(data)\n",
    "        \n",
    "        origDisp = km.inertia_\n",
    "\n",
    "        # Calculate gap statistic\n",
    "        gap = np.log(np.mean(refDisps)) - np.log(origDisp)\n",
    "\n",
    "        # Assign this loop's gap statistic to gaps\n",
    "        gaps[gap_index] = gap\n",
    "        \n",
    "        resultsdf = resultsdf.append({'clusterCount':k, 'gap':gap}, ignore_index=True)\n",
    "\n",
    "    return (gaps.argmax() + 1, resultsdf)  # Plus 1 because index of 0 means 1 cluster is optimal, index 2 = 3 clusters are optimal\n",
    "\n",
    "k, _ = optimalK(train_data_pca)\n",
    "print(f\"The optimal number of clusters is: {k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train k-means model with optimal number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=k, n_jobs=-1)\n",
    "kmeans.fit(train_data_pca)\n",
    "\n",
    "# build a dataframe to contain the pitch classifications\n",
    "labels = pd.DataFrame(kmeans.labels_)\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### turn the labels into counts of pitch type for each pitcher "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, one-hot-encode the label df\n",
    "ohe = OneHotEncoder()\n",
    "labels_ohe = pd.DataFrame(ohe.fit_transform(labels).toarray())\n",
    "\n",
    "# give the new columns names\n",
    "pitch_labels = ['pitch_type_'+str(i) for i in range(len(labels_ohe.columns.tolist()))]\n",
    "labels_ohe.columns = pitch_labels\n",
    "\n",
    "# merge the pitch type data with the pitcher's ID and name\n",
    "pitch_data = pd.merge(pitcherID, labels_ohe, left_index=True, right_index=True)\n",
    "\n",
    "# groupby on the pitcher ID/name and sum the rows\n",
    "pitch_data = pitch_data.groupby(['pitcher', 'player_name']).sum()\n",
    "pitch_data.reset_index(inplace=True, drop=False)\n",
    "\n",
    "# finally, turn the pitch counts into percentages\n",
    "pitch_data_pct = pd.DataFrame()\n",
    "for i in range(len(pitch_data)):\n",
    "    temp_df = pd.DataFrame(pitch_data.iloc[i]).T\n",
    "    pitch_sum = sum(temp_df.iloc[0,2:])\n",
    "    temp_df.iloc[0,2:] = temp_df.iloc[0,2:] / pitch_sum\n",
    "    pitch_data_pct = pitch_data_pct.append(temp_df)\n",
    "    \n",
    "data_file_path = \"/home/chris/data/baseball/PitchClustering/\"\n",
    "pitch_data_pct.to_csv(data_file_path + \"pitch_11types.csv\", index=False)\n",
    "    \n",
    "print(pitch_data_pct.shape)\n",
    "pitch_data_pct.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Batter's Prior Zone Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the hit zone data from the outcome calculated above\n",
    "data_file_path = \"/home/chris/data/baseball/HitZone/\"\n",
    "batter_zone_data = pd.read_csv(data_file_path + \"train_4zones.csv\")\n",
    "batter_zone_data = batter_zone_data[['batter', 'hit_zone']]\n",
    "batter_zone_data.set_index('batter', inplace=True)\n",
    "\n",
    "# one-hot-encode the hit_zone column\n",
    "ohe = OneHotEncoder()\n",
    "zones_ohe = pd.DataFrame(ohe.fit_transform(batter_zone_data).toarray())\n",
    "zones_ohe.index = batter_zone_data.index\n",
    "zones_ohe.columns = ['zone_1', 'zone_2', 'zone_3', 'zone_4']\n",
    "zones_ohe.reset_index(inplace=True, drop=False)\n",
    "\n",
    "# group by batter ID and sum\n",
    "batter_zone_data = zones_ohe.groupby('batter').sum()\n",
    "\n",
    "# finally, turn the pitch counts into percentages\n",
    "batter_zone_data_pct = pd.DataFrame()\n",
    "for i in range(len(batter_zone_data)):\n",
    "    temp_df = pd.DataFrame(batter_zone_data.iloc[i]).T\n",
    "    pitch_sum = sum(temp_df.iloc[0,:])\n",
    "    temp_df.iloc[0,:] = temp_df.iloc[0,:] / pitch_sum\n",
    "    batter_zone_data_pct = batter_zone_data_pct.append(temp_df)\n",
    "    \n",
    "batter_zone_data_pct.reset_index(inplace=True, drop=False)\n",
    "batter_zone_data_pct.columns = ['batter', 'batter_zone_1', 'batter_zone_2', 'batter_zone_3', 'batter_zone_4']\n",
    "\n",
    "batter_zone_data_pct.to_csv(\"/home/chris/data/baseball/HitZone/batter_prior_4zones.csv\", index=False)\n",
    "\n",
    "print(batter_zone_data_pct.shape)\n",
    "batter_zone_data_pct.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batter_zone_data_pct.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Complete Feature Set for Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Game Situation Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(start, end):\n",
    "\n",
    "    data = statcast(start_dt=start, end_dt=end)\n",
    "\n",
    "    # just keep the \"events\" (i.e., the end result of an at-bat)\n",
    "    data = data[~pd.isnull(data['events'])]\n",
    "\n",
    "    # remove events that don't involve the ball being put into play in a meaningful way \n",
    "    # (i.e., no strikeouts, walks, sacrifice bunts, caught stealing, hit by pitch, etc.)\n",
    "    inplay_event_list = ['field_out', 'sac_fly', 'force_out', 'field_error', 'double', 'home_run', \n",
    "                         'grounded_into_double_play', 'fielders_choice', 'fielders_choice_out', 'triple', \n",
    "                         'double_play']\n",
    "    data = data[data['events'].isin(inplay_event_list)]\n",
    "\n",
    "    # trim down the features \n",
    "    cols_to_keep = ['game_pk', 'index', 'batter', 'pitcher', 'stand', 'p_throws', 'balls', 'strikes', 'outs_when_up', \n",
    "                    'inning', 'on_1b', 'on_2b', 'on_3b', 'bat_score', 'fld_score']\n",
    "    data = data[cols_to_keep]\n",
    "\n",
    "    # make sure index columns are int's\n",
    "    for col in ['game_pk', 'index', 'batter', 'pitcher']:\n",
    "        data[col] = data[col].astype(int)\n",
    "\n",
    "    data['bat_right'] = data['stand'].apply(lambda x: x == 'R') \n",
    "    data['pitch_right'] = data['p_throws'].apply(lambda x: x == 'R')\n",
    "    data.drop(['stand', 'p_throws'], axis=1, inplace=True)\n",
    "\n",
    "    for col in ['on_1b', 'on_2b', 'on_3b']:\n",
    "        data[col] = data[col].apply(lambda x: x == x)\n",
    "\n",
    "    data['score_diff'] = data['bat_score'] - data['fld_score']\n",
    "    data.drop(['bat_score', 'fld_score'], axis=1, inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Statcast data (from 2015-2018) so we can get spin rate, etc.\n",
    "train_data_dates = [('2015-04-05', '2015-10-04'),\n",
    "                    ('2016-04-03', '2016-10-02'),\n",
    "                    ('2017-04-02', '2017-10-01'),\n",
    "                    ('2018-03-29', '2018-10-01')]\n",
    "\n",
    "# build a list of dataframes (one for each year)\n",
    "train_data_list = []\n",
    "for dates in train_data_dates:\n",
    "    df = get_features(start=dates[0], end=dates[1])\n",
    "    train_data_list.append(df)\n",
    "    \n",
    "# concat the list of dataframes into one large dataframe\n",
    "train_data = pd.concat(train_data_list)\n",
    "\n",
    "# write to file\n",
    "data_file_path = \"/home/chris/data/baseball/HitFeatures/\"\n",
    "train_data.to_csv(data_file_path + \"train.csv\", index=False)\n",
    "\n",
    "print(train_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the Game Situation, Pitcher and Batter Features along with the Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_situation_df = pd.read_csv(\"/home/chris/data/baseball/HitFeatures/train.csv\")\n",
    "\n",
    "pitch_type_df = pd.read_csv(\"/home/chris/data/baseball/PitchClustering/pitch_11types.csv\")\n",
    "\n",
    "pitch_type_df.drop('player_name', axis=1, inplace=True)\n",
    "pitch_type_df['pitcher'] = pitch_type_df['pitcher'].astype(int)\n",
    "\n",
    "batter_zone_df = pd.read_csv(\"/home/chris/data/baseball/HitZone/batter_prior_4zones.csv\")\n",
    "\n",
    "outcome_df = pd.read_csv(\"/home/chris/data/baseball/HitZone/train_4zones.csv\")\n",
    "\n",
    "full_data = pd.merge(game_situation_df, pitch_type_df, on=\"pitcher\")\n",
    "full_data = pd.merge(full_data, batter_zone_df, on=\"batter\")\n",
    "full_data = pd.merge(outcome_df, full_data, on=['game_pk', 'index', 'batter', 'pitcher'])\n",
    "\n",
    "print(game_situation_df.shape)\n",
    "print(pitch_type_df.shape)\n",
    "print(batter_zone_df.shape)\n",
    "print(outcome_df.shape)\n",
    "print(full_data.shape)\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = full_data.drop(['game_pk', 'index', 'batter', 'pitcher'], axis=1)\n",
    "\n",
    "# split the dataframe into a feature set and an outcome column\n",
    "X = full_data.drop('hit_zone', axis=1)\n",
    "y = full_data['hit_zone']\n",
    "\n",
    "# split the data into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# train an XGBoost model\n",
    "# ----------------------\n",
    "\n",
    "# small set of hyperparameters to optimize over\n",
    "xgb_params = {\"max_depth\": (3, 5, 10, 15, 20),\n",
    "              \"learning_rate\": (0.01, 0.5, 0.1, 0.2, 0.4),\n",
    "              \"gamma\": (0, 33, 66, 100),\n",
    "              \"min_child_weight\": (0, 33, 66, 100),\n",
    "              \"colsample_bytree\": (0.5, 0.75, 1),\n",
    "              \"subsample\": (0.5, 0.75, 1),}\n",
    "\n",
    "# perform the paramater grid search using 5-fold cross validation\n",
    "xgb_opt = GridSearchCV(XGBClassifier(objective='multi:softprob', num_class=4), \n",
    "                       param_grid=xgb_params, cv=5, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "\n",
    "#xgb_opt = XGBClassifier(objective='multi:softprob', num_class=4)\n",
    "\n",
    "# perform fit and make predictions\n",
    "xgb_opt.fit(X_train, y_train)\n",
    "y_pred = xgb_opt.predict(X_test)\n",
    "y_prob = xgb_opt.predict_proba(X_test)\n",
    "\n",
    "# compute accuracy\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 1)\n",
    "\n",
    "# print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_train.columns.tolist()\n",
    "importances = list(xgb_opt.feature_importances_)\n",
    "for i in range(len(features)):\n",
    "    print(features[i] + \"\\t\" + str(importances[i] * 100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
