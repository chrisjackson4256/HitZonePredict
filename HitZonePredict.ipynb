{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game of Zones: Using ML to Predict the Outcome of an MLB At Bat\n",
    "\n",
    "Goal: predict where the batter is most likely to hit the ball (zones of the field) in an at-bat given the situation and the pitcher he is facing\n",
    "    \n",
    "Input Data: \n",
    "- the pitcher's repertoire: given that each pitcher has a different arsenal of pitches and each pitch moves differently, we use a cluster analysis to categorize pitch types.  In this way, we put each pitcher on the same footing.\n",
    "\n",
    "- pitcher stats such as groundball and flyball rates\n",
    "\n",
    "- the game situation: the inning (and top/bottom), the number of outs, positions of baserunners, the count, positions of fielders(?)\n",
    "\n",
    "- the batter's priors: distribution of batted balls into zones\n",
    "\n",
    "- any other batter data?\n",
    "\n",
    "Output: \n",
    "- probabilities for each zone on the field where the batter can hit the ball\n",
    "\n",
    "- contributing factors for each prediction (things the defensive team could use to intervene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pybaseball import statcast, pitching_stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "%matplotlib inline\n",
    "\n",
    "from get_data import get_data, get_hit_zone, get_pitch_data, get_situation_data\n",
    "from pitch_clustering import pitch_clustering\n",
    "from batter_zone import get_batter_zone_data\n",
    "\n",
    "# use Statcast data (from 2015-2018) so we can get spin rate, etc.\n",
    "train_data_dates = [('2015-04-05', '2015-10-04'),      # 2015 data\n",
    "                    ('2016-04-03', '2016-10-02'),       # 2016 data\n",
    "                    ('2017-04-02', '2017-10-01'),       # 2017 data\n",
    "                    ('2018-03-29', '2018-10-01')]       # 2018 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the outcome data\n",
    "outcome_data = get_data(get_hit_zone, train_data_dates)\n",
    "\n",
    "# write to file\n",
    "outcome_data.to_csv(\"./outcome.csv\", index=False)\n",
    "\n",
    "print(f\"Shape of the outcome data: {outcome_data.shape}\")\n",
    "outcome_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Pitcher Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the outcome data\n",
    "pitch_data = get_data(get_pitch_data, train_data_dates)\n",
    "\n",
    "# write to file\n",
    "pitch_data.to_csv(\"./pitch.csv\", index=False)\n",
    "\n",
    "# print the number of pitchers in the data set\n",
    "print(f\"Number of pitchers in the data: {len(pitch_data['pitcher'].unique())}\")\n",
    "\n",
    "print(f\"Shape of training data: {pitch_data.shape}\")\n",
    "\n",
    "pitch_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform PCA & Clustering on Pitch Data... and Add in Groundball/Flyball Percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in pitch data\n",
    "pitch_data = pd.read_csv(\"./pitch.csv\")\n",
    "\n",
    "# perform PCA and K-Means clustering\n",
    "pitch_data = pitch_clustering(pitch_data)\n",
    "\n",
    "# write to file\n",
    "pitch_data.to_csv(\"./pitch.csv\")\n",
    "\n",
    "pitch_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Batter's Prior Zone Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the hit zone data from the outcome (calculated above)\n",
    "batter_zone_data = pd.read_csv(\"./outcome.csv\")\n",
    "\n",
    "batter_zone_data_pct = get_batter_zone_data(batter_zone_data)\n",
    "\n",
    "batter_zone_data_pct.to_csv(\"./batter_zones.csv\", index=False)\n",
    "\n",
    "print(batter_zone_data_pct.shape)\n",
    "batter_zone_data_pct.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Game Situation Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "situation_data = get_data(get_situation_data, train_data_dates)\n",
    "\n",
    "# write to file\n",
    "situation_data.to_csv(\"./situation.csv\", index=False)\n",
    "\n",
    "print(situation_data.shape)\n",
    "situation_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the Game Situation, Pitcher and Batter Features along with the Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# game situation data\n",
    "game_situation_df = pd.read_csv(\"./situation.csv\")\n",
    "\n",
    "# pitch type data\n",
    "pitch_type_df = pd.read_csv(\"./pitch.csv\")\n",
    "pitch_type_df.drop('player_name', axis=1, inplace=True)\n",
    "pitch_type_df['pitcher'] = pitch_type_df['pitcher'].astype(int)\n",
    "\n",
    "# batter's prior hit zone distribution\n",
    "batter_zone_df = pd.read_csv(\"./batter_zones.csv\")\n",
    "\n",
    "# the outcome of the at-bat\n",
    "outcome_df = pd.read_csv(\"./outcome.csv\")\n",
    "\n",
    "# combine all of the data sources into one dataframe\n",
    "full_data = pd.merge(game_situation_df, pitch_type_df, on=\"pitcher\")\n",
    "full_data = pd.merge(full_data, batter_zone_df, on=\"batter\")\n",
    "full_data = pd.merge(outcome_df, full_data, on=['game_pk', 'index', 'batter', 'pitcher'])\n",
    "\n",
    "print(full_data.shape)\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Data into Train/Test Feature and Target Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop index columns for training\n",
    "full_data = full_data.drop(['game_pk', 'index', 'batter', 'pitcher'], axis=1)\n",
    "\n",
    "# keep index columns in a separate dataframe for future use\n",
    "index_data = full_data[['game_pk', 'index', 'batter', 'pitcher']]\n",
    "\n",
    "# split the dataframe into a feature set and an outcome column\n",
    "X = full_data.drop('hit_zone', axis=1)\n",
    "y = full_data['hit_zone']\n",
    "\n",
    "# split the data into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train an XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# train an XGBoost model\n",
    "# ----------------------\n",
    "\n",
    "# small set of hyperparameters to optimize over\n",
    "# xgb_params = {\"max_depth\": (3, 5, 10, 15, 20),\n",
    "#               \"learning_rate\": (0.01, 0.5, 0.1, 0.2, 0.4),\n",
    "#               \"gamma\": (0, 33, 66, 100),\n",
    "#               \"min_child_weight\": (0, 33, 66, 100),\n",
    "#               \"colsample_bytree\": (0.5, 0.75, 1),\n",
    "#               \"subsample\": (0.5, 0.75, 1),}\n",
    "\n",
    "# # perform the paramater grid search using 5-fold cross validation\n",
    "# xgb_opt = GridSearchCV(XGBClassifier(objective='multi:softprob', num_class=4), \n",
    "#                        param_grid=xgb_params, cv=5, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "\n",
    "xgb_opt = XGBClassifier(objective='multi:softprob', num_class=4)\n",
    "\n",
    "# perform fit and make predictions\n",
    "xgb_opt.fit(X_train, y_train)\n",
    "y_pred = xgb_opt.predict(X_test)\n",
    "y_prob = xgb_opt.predict_proba(X_test)\n",
    "\n",
    "# compute accuracy\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 1)\n",
    "\n",
    "# the naive model - the max of the prior probabilities\n",
    "def naive_model(df):\n",
    "    df = df[['batter_zone_1', 'batter_zone_2', 'batter_zone_3', 'batter_zone_4']]\n",
    "    df.columns = [1, 2, 3, 4]\n",
    "    return df.idxmax(axis=1)\n",
    "y_naive = naive_model(X_test).as_matrix()\n",
    "\n",
    "# compute naive accuracy\n",
    "naive_accuracy = round(accuracy_score(y_test, y_naive) * 100, 1)\n",
    "\n",
    "print(f\"Accuracy of the Naive model: {naive_accuracy}%\")\n",
    "print(f\"Accuracy of the XGBoost model: {accuracy}%\")\n",
    "\n",
    "# print the confusion matrix\n",
    "print()\n",
    "print(\"The Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2015 Data Only:\n",
    "---------------\n",
    "Accuracy of the Naive model: 37.7%\n",
    "Accuracy of the XGBoost model: 38.6%\n",
    "\n",
    "The Confusion Matrix: \n",
    "[[ 893  333 2018 1204]\n",
    " [ 281  731 2403 1176]\n",
    " [ 541  504 5440 2272]\n",
    " [ 579  432 3969 2814]]\n",
    " \n",
    " \n",
    "2016 Data Only:\n",
    "---------------\n",
    "Accuracy of the Naive model: 38.1%\n",
    "Accuracy of the XGBoost model: 38.3%\n",
    "\n",
    "The Confusion Matrix: \n",
    "[[ 552  231 1792  972]\n",
    " [ 177  605 2029 1051]\n",
    " [ 342  433 4515 1919]\n",
    " [ 368  343 3436 2440]]\n",
    " \n",
    " \n",
    "2017 Data Only:\n",
    "---------------\n",
    "Accuracy of the Naive model: 38.3%\n",
    "Accuracy of the XGBoost model: 38.4%\n",
    "\n",
    "The Confusion Matrix: \n",
    "[[ 324  185 1483  948]\n",
    " [ 105  471 1675 1085]\n",
    " [ 172  345 3735 1852]\n",
    " [ 188  310 2959 2529]]\n",
    " \n",
    " \n",
    "2018 Data Only:\n",
    "---------------\n",
    "Accuracy of the Naive model: 37.0%\n",
    "Accuracy of the XGBoost model: 38.2%\n",
    "\n",
    "The Confusion Matrix: \n",
    "[[ 507  193 1141  780]\n",
    " [ 153  549 1287 1061]\n",
    " [ 299  344 2782 1652]\n",
    " [ 317  308 2159 2159]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_train.columns.tolist()\n",
    "importances = list(xgb_opt.feature_importances_)\n",
    "for i in range(len(features)):\n",
    "    print(features[i] + \"\\t\" + str(importances[i] * 100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
